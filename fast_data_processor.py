#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é«˜æ€§èƒ½ç”¨æˆ·ç”»åƒæ•°æ®å¤„ç†è„šæœ¬ - ä¼˜åŒ–ç‰ˆ
é’ˆå¯¹å¤§æ•°æ®é‡è¿›è¡Œæ€§èƒ½ä¼˜åŒ–
"""

import pandas as pd
import numpy as np
import json
from collections import Counter, defaultdict
from datetime import datetime
import os

class FastUserProfileProcessor:
    def __init__(self):
        """åˆå§‹åŒ–å¤„ç†å™¨"""
        self.users_df = None
        self.messages_df = None

        # ç®€åŒ–çš„å…³é”®è¯åº“
        self.content_keywords = {
            'æŠ€æœ¯å‹': ['ç¼–ç¨‹', 'ä»£ç ', 'æŠ€æœ¯', 'java', 'python', 'å¼€å‘', 'ç®—æ³•'],
            'å­¦ä¹ å‹': ['å­¦ä¹ ', 'è€ƒè¯•', 'å¤ä¹ ', 'ä½œä¸š', 'è¯¾ç¨‹', 'æˆç»©'],
            'ç”Ÿæ´»å‹': ['å®¿èˆ', 'é£Ÿå ‚', 'ç”Ÿæ´»', 'ç¡è§‰', 'åƒé¥­'],
            'å¨±ä¹å‹': ['å“ˆå“ˆ', 'æ¸¸æˆ', 'å¥½ç©', 'æç¬‘', 'ğŸ˜‚'],
            'é—²èŠå‹': ['èŠå¤©', 'è¯è¯´', 'å¯¹äº†', 'æ— èŠ']
        }

        self.question_words = ['ï¼Ÿ', '?', 'å—', 'æ€ä¹ˆ', 'ä¸ºä»€ä¹ˆ', 'ä»€ä¹ˆ']
        self.positive_words = ['å¥½', 'æ£’', 'èµ', 'ä¸é”™', 'å¼€å¿ƒ']
        self.negative_words = ['ä¸å¥½', 'ç³Ÿç³•', 'éš¾è¿‡', 'çƒ¦']

    def load_data(self):
        """å¿«é€ŸåŠ è½½æ•°æ®"""
        print("å¿«é€ŸåŠ è½½æ•°æ®...")
        base_path = "ç”¨äºæ•°æ®åˆ†æçš„ç”¨æˆ·æ•°æ®/data_backup_0901"

        try:
            # åªè¯»å–å¿…è¦çš„åˆ—
            user_cols = ['user_id', 'nickname', 'group_name', 'platform']
            message_cols = ['user_id', 'hour', 'date', 'message_content', 'reply_to', 'is_ai_message']

            self.users_df = pd.read_csv(f"{base_path}/users_enhanced.csv", encoding='utf-8', usecols=user_cols)

            msg1 = pd.read_csv(f"{base_path}/messages_backup_data_enhanced.csv", encoding='utf-8', usecols=message_cols)
            msg2 = pd.read_csv(f"{base_path}/messages_maibot_main_enhanced.csv", encoding='utf-8', usecols=message_cols)

            # åˆå¹¶å¹¶åªè¿‡æ»¤æ­¦å°çººæœºå™¨äºº
            self.messages_df = pd.concat([msg1, msg2], ignore_index=True)
            # åªè¿‡æ»¤æ­¦å°çººæœºå™¨äºº(user_id: 3655943918)ï¼Œå…¶ä»–ç”¨æˆ·éƒ½æ˜¯çœŸå®ç”¨æˆ·
            self.messages_df = self.messages_df[
                (self.messages_df['user_id'] != 3655943918) &
                (self.messages_df.get('user_nickname', '') != 'æ­¦å°çºº')
            ]

            # é¢„å¤„ç†æ¶ˆæ¯å†…å®¹
            self.messages_df['message_content'] = self.messages_df['message_content'].fillna('').astype(str)

            print(f"æ•°æ®åŠ è½½å®Œæˆï¼šç”¨æˆ· {len(self.users_df)}, æ¶ˆæ¯ {len(self.messages_df)}")
            return True

        except Exception as e:
            print(f"æ•°æ®åŠ è½½å¤±è´¥ï¼š{e}")
            return False

    def classify_content_type(self, messages):
        """å¿«é€Ÿå†…å®¹åˆ†ç±»"""
        if len(messages) == 0:
            return 'é—²èŠå‹', 0.5

        type_scores = defaultdict(int)
        total_chars = 0

        for content in messages:
            total_chars += len(content)
            for content_type, keywords in self.content_keywords.items():
                if any(kw in content for kw in keywords):
                    type_scores[content_type] += 1

        if not type_scores:
            return 'é—²èŠå‹'

        max_type = max(type_scores, key=type_scores.get)

        return max_type

    def analyze_time_pattern(self, hours):
        """å¿«é€Ÿæ—¶é—´æ¨¡å¼åˆ†æ"""
        if len(hours) == 0:
            return 'æœªçŸ¥', {}

        hour_counts = Counter(hours)
        total = len(hours)

        # æ—¶æ®µç»Ÿè®¡
        morning = sum(hour_counts.get(h, 0) for h in range(6, 10)) / total
        evening = sum(hour_counts.get(h, 0) for h in range(18, 23)) / total
        night = sum(hour_counts.get(h, 0) for h in [23, 0, 1, 2, 3, 4, 5]) / total
        regular = sum(hour_counts.get(h, 0) for h in range(8, 23)) / total

        # ç®€åŒ–åˆ†ç±»
        if morning > 0.4:
            time_type = 'æ—©ä¸Šå‹'
        elif night > 0.3:
            time_type = 'ç†¬å¤œå‹'
        elif regular > 0.8:
            time_type = 'è§„å¾‹å‹'
        else:
            time_type = 'ä¸è§„å¾‹å‹'

        return time_type, {
            'morning_ratio': round(morning, 3),
            'evening_ratio': round(evening, 3),
            'night_ratio': round(night, 3)
        }

    def analyze_social_behavior(self, messages_data):
        """å¿«é€Ÿç¤¾äº¤è¡Œä¸ºåˆ†æ"""
        if len(messages_data) == 0:
            return 'ä¸€èˆ¬å‹', {}

        contents = messages_data['message_content'].tolist()
        replies = messages_data['reply_to'].notna().sum()

        # å¿«é€Ÿç»Ÿè®¡
        question_count = sum(1 for content in contents if any(qw in content for qw in self.question_words))

        total = len(contents)
        question_rate = question_count / total
        reply_rate = replies / total

        # ç®€åŒ–åˆ†ç±»
        if question_rate > 0.2:
            social_type = 'ä¸»åŠ¨å‹'
        elif reply_rate > 0.5:
            social_type = 'é™„å’Œå‹'
        else:
            social_type = 'ä¸€èˆ¬å‹'

        return social_type, {
            'question_rate': round(question_rate, 3),
            'reply_rate': round(reply_rate, 3)
        }

    def analyze_sentiment(self, contents):
        """å¿«é€Ÿæƒ…æ„Ÿåˆ†æ"""
        if len(contents) == 0:
            return 'ä¸­æ€§', 0.5

        positive_count = sum(1 for content in contents if any(pw in content for pw in self.positive_words))
        negative_count = sum(1 for content in contents if any(nw in content for nw in self.negative_words))

        total_emotional = positive_count + negative_count
        if total_emotional == 0:
            return 'ä¸­æ€§', 0.5

        positive_ratio = positive_count / total_emotional

        if positive_ratio > 0.6:
            sentiment = 'ç§¯æå‹'
        elif positive_ratio < 0.4:
            sentiment = 'æ¶ˆæå‹'
        else:
            sentiment = 'ä¸­æ€§'

        return sentiment, round(positive_ratio, 3)

    def process_user_fast(self, user_id, user_info, user_messages):
        """å¿«é€Ÿå¤„ç†å•ä¸ªç”¨æˆ·"""
        msg_count = len(user_messages)

        if msg_count == 0:
            return {
                'user_id': str(user_id),
                'nickname': user_info.get('nickname', 'æœªçŸ¥'),
                'main_group': user_info.get('group_name', 'æœªçŸ¥'),
                'message_count': 0,
                'dimensions': {
                    'message_volume': {'level': 'æå°‘å‘è¨€äºº', 'count': 0},
                    'content_type': {'type': 'é—²èŠå‹'},
                    'time_pattern': {'type': 'æœªçŸ¥', 'stats': {}},
                    'social_behavior': {'type': 'ä¸€èˆ¬å‹', 'metrics': {}},
                    'sentiment': {'type': 'ä¸­æ€§', 'score': 0.5}
                },
                'tags': ['ğŸ‘€æ½œæ°´è§‚å¯Ÿ', 'ğŸ’­é—²èŠå‹', 'ğŸ˜ä¸­æ€§']
            }

        # å¿«é€Ÿåˆ†æ
        contents = user_messages['message_content'].tolist()
        hours = user_messages['hour'].dropna().tolist()

        content_type = self.classify_content_type(contents)
        time_type, time_stats = self.analyze_time_pattern(hours)
        social_type, social_metrics = self.analyze_social_behavior(user_messages)
        sentiment_type, sentiment_score = self.analyze_sentiment(contents)

        # ç”Ÿæˆæ ‡ç­¾
        tags = []

        # å‘è¨€é‡æ ‡ç­¾
        if msg_count > 200:
            volume_level = 'ä¸»è¦å‘è¨€äºº'
            tags.append('ğŸ”¥è¯é¢˜ä¸»å¯¼è€…')
        elif msg_count > 50:
            volume_level = 'ç¨³å®šå‘è¨€äºº'
            tags.append('ğŸ’¬ç¨³å®šå‘è¨€äºº')
        elif msg_count > 10:
            volume_level = 'å°‘é‡å‘è¨€äºº'
            tags.append('ğŸ¤å¶å°”å‘è¨€')
        else:
            volume_level = 'æå°‘å‘è¨€äºº'
            tags.append('ğŸ‘€æ½œæ°´è§‚å¯Ÿ')

        # ç±»å‹æ ‡ç­¾
        type_emoji = {'æŠ€æœ¯å‹': 'ğŸ’»', 'å­¦ä¹ å‹': 'ğŸ“š', 'ç”Ÿæ´»å‹': 'ğŸ ', 'å¨±ä¹å‹': 'ğŸ˜„', 'é—²èŠå‹': 'ğŸ’­'}
        tags.append(f"{type_emoji.get(content_type, 'ğŸ’­')}{content_type}")

        # æ—¶é—´æ ‡ç­¾
        time_emoji = {'æ—©ä¸Šå‹': 'ğŸŒ…', 'ç†¬å¤œå‹': 'ğŸŒ™', 'è§„å¾‹å‹': 'â°', 'ä¸è§„å¾‹å‹': 'ğŸ”€'}
        tags.append(f"{time_emoji.get(time_type, 'â°')}{time_type}")

        # ç¤¾äº¤æ ‡ç­¾
        social_emoji = {'ä¸»åŠ¨å‹': 'ğŸš€', 'é™„å’Œå‹': 'ğŸ‘', 'ä¸€èˆ¬å‹': 'ğŸ¤'}
        tags.append(f"{social_emoji.get(social_type, 'ğŸ¤')}{social_type}")

        # æƒ…æ„Ÿæ ‡ç­¾
        sentiment_emoji = {'ç§¯æå‹': 'â˜€ï¸', 'æ¶ˆæå‹': 'â˜ï¸', 'ä¸­æ€§': 'ğŸ˜'}
        tags.append(f"{sentiment_emoji.get(sentiment_type, 'ğŸ˜')}{sentiment_type}")

        return {
            'user_id': str(user_id),
            'nickname': user_info.get('nickname', 'æœªçŸ¥'),
            'main_group': user_info.get('group_name', 'æœªçŸ¥ç¾¤ç»„'),
            'all_groups': user_info.get('all_groups', [user_info.get('group_name', 'æœªçŸ¥ç¾¤ç»„')]),
            'message_count': msg_count,
            'avg_message_length': round(np.mean([len(c) for c in contents]), 1) if contents else 0,

            'dimensions': {
                'message_volume': {
                    'level': volume_level,
                    'count': msg_count,
                    'rank': 0  # åç»­è®¡ç®—
                },
                'content_type': {
                    'type': content_type
                },
                'time_pattern': {
                    'type': time_type,
                    'stats': time_stats
                },
                'social_behavior': {
                    'type': social_type,
                    'metrics': social_metrics
                },
                'sentiment': {
                    'type': sentiment_type,
                    'score': sentiment_score
                }
            },

            'profile_summary': {
                'tags': tags,
                'description': f"{content_type}çš„{time_type}ç”¨æˆ·",
                'active_score': min(msg_count / 100, 1.0)
            }
        }

    def process_all_users_fast(self):
        """å¿«é€Ÿå¤„ç†æ‰€æœ‰ç”¨æˆ·"""
        print("å¼€å§‹å¿«é€Ÿå¤„ç†ç”¨æˆ·ç”»åƒ...")

        # é¢„å¤„ç†ç”¨æˆ·ä¿¡æ¯
        user_info_dict = {}
        for _, user_row in self.users_df.iterrows():
            user_id = user_row['user_id']
            if user_id not in user_info_dict:
                user_info_dict[user_id] = {
                    'nickname': user_row['nickname'],
                    'group_name': user_row['group_name'],
                    'platform': user_row.get('platform', 'unknown'),
                    'all_groups': [user_row['group_name']]
                }
            else:
                if user_row['group_name'] not in user_info_dict[user_id]['all_groups']:
                    user_info_dict[user_id]['all_groups'].append(user_row['group_name'])

        # æ‰¹é‡å¤„ç†æ¶ˆæ¯æ•°æ®
        user_message_groups = self.messages_df.groupby('user_id')
        processed_users = []

        total_users = len(user_info_dict)
        print(f"éœ€è¦å¤„ç† {total_users} ä¸ªç”¨æˆ·")

        for i, (user_id, user_info) in enumerate(user_info_dict.items()):
            if i % 100 == 0:
                print(f"å¤„ç†è¿›åº¦: {i+1}/{total_users}")

            # è·å–ç”¨æˆ·æ¶ˆæ¯
            if user_id in user_message_groups.groups:
                user_messages = user_message_groups.get_group(user_id)
            else:
                user_messages = pd.DataFrame()

            # å¿«é€Ÿå¤„ç†
            user_profile = self.process_user_fast(user_id, user_info, user_messages)
            processed_users.append(user_profile)

        # è®¡ç®—æ’å
        processed_users.sort(key=lambda x: x['message_count'], reverse=True)
        for i, user in enumerate(processed_users):
            user['dimensions']['message_volume']['rank'] = i + 1

        print(f"å¿«é€Ÿå¤„ç†å®Œæˆï¼Œå…± {len(processed_users)} ä¸ªç”¨æˆ·")
        return processed_users

    def calculate_stats_fast(self, users_data):
        """å¿«é€Ÿè®¡ç®—ç»Ÿè®¡æ•°æ®"""
        print("è®¡ç®—å…¨å±€ç»Ÿè®¡...")

        stats = {
            'total_users': len(users_data),
            'total_messages': sum(u['message_count'] for u in users_data),
            'total_groups': len(set(u['main_group'] for u in users_data)),
            'message_volume_distribution': Counter(),
            'content_type_distribution': Counter(),
            'time_pattern_distribution': Counter(),
            'social_behavior_distribution': Counter(),
            'sentiment_distribution': Counter(),
            'update_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }

        # é‡æ–°åˆ†ç±»å‘è¨€é‡ï¼ˆåŸºäºå®é™…åˆ†å¸ƒï¼‰
        message_counts = [u['message_count'] for u in users_data]
        message_counts.sort(reverse=True)

        total = len(message_counts)
        if total > 10:
            # è®¡ç®—æ­£ç¡®çš„ç™¾åˆ†ä½é˜ˆå€¼
            # å‰15%çš„ä¸‹ç•Œï¼ˆä¸»è¦å‘è¨€äººé—¨æ§›ï¼‰
            major_threshold_index = int(total * 0.15) - 1  # ç¬¬15%ä½ç½®
            # å‰60%çš„ä¸‹ç•Œï¼ˆç¨³å®šå‘è¨€äººé—¨æ§›ï¼‰
            stable_threshold_index = int(total * 0.60) - 1  # ç¬¬60%ä½ç½®
            # å‰85%çš„ä¸‹ç•Œï¼ˆå°‘é‡å‘è¨€äººé—¨æ§›ï¼‰
            occasional_threshold_index = int(total * 0.85) - 1  # ç¬¬85%ä½ç½®

            thresholds = {
                'major': message_counts[major_threshold_index] if major_threshold_index >= 0 else message_counts[0],
                'stable': message_counts[stable_threshold_index] if stable_threshold_index >= 0 else 1,
                'occasional': message_counts[occasional_threshold_index] if occasional_threshold_index >= 0 else 1
            }

            print(f"åˆ†ç±»é˜ˆå€¼è®¡ç®—: æ€»ç”¨æˆ·{total}äºº")
            print(f"ä¸»è¦å‘è¨€äººé˜ˆå€¼(å‰15%): >= {thresholds['major']}æ¡æ¶ˆæ¯")
            print(f"ç¨³å®šå‘è¨€äººé˜ˆå€¼(15-60%): >= {thresholds['stable']}æ¡æ¶ˆæ¯")
            print(f"å°‘é‡å‘è¨€äººé˜ˆå€¼(60-85%): >= {thresholds['occasional']}æ¡æ¶ˆæ¯")
        else:
            thresholds = {'major': 100, 'stable': 20, 'occasional': 5}

        # æ›´æ–°åˆ†ç±»å¹¶ç»Ÿè®¡
        for user in users_data:
            msg_count = user['message_count']

            if msg_count >= thresholds['major']:
                level = 'ä¸»è¦å‘è¨€äºº'
            elif msg_count >= thresholds['stable']:
                level = 'ç¨³å®šå‘è¨€äºº'
            elif msg_count >= thresholds['occasional']:
                level = 'å°‘é‡å‘è¨€äºº'
            else:
                level = 'æå°‘å‘è¨€äºº'

            user['dimensions']['message_volume']['level'] = level
            stats['message_volume_distribution'][level] += 1

            # å…¶ä»–ç»Ÿè®¡
            stats['content_type_distribution'][user['dimensions']['content_type']['type']] += 1
            stats['time_pattern_distribution'][user['dimensions']['time_pattern']['type']] += 1
            stats['social_behavior_distribution'][user['dimensions']['social_behavior']['type']] += 1
            stats['sentiment_distribution'][user['dimensions']['sentiment']['type']] += 1

        # è½¬æ¢ä¸ºæ™®é€šå­—å…¸
        for key in ['message_volume_distribution', 'content_type_distribution', 'time_pattern_distribution', 'social_behavior_distribution', 'sentiment_distribution']:
            stats[key] = dict(stats[key])

        return stats

    def generate_fast_analytics(self):
        """å¿«é€Ÿç”Ÿæˆåˆ†ææ•°æ®"""
        if not self.load_data():
            return None

        users_data = self.process_all_users_fast()
        stats = self.calculate_stats_fast(users_data)

        return {
            'stats': stats,
            'users': users_data,
            'metadata': {
                'processing_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'processor_version': 'fast_v1.0',
                'features': ['å¿«é€Ÿå‘è¨€é‡åˆ†æ', 'å†…å®¹ç±»å‹åˆ†ç±»', 'æ—¶é—´ä¹ æƒ¯åˆ†æ', 'ç¤¾äº¤è¡Œä¸ºåˆ†æ', 'æƒ…æ„Ÿå€¾å‘åˆ†æ']
            }
        }

    def clean_nan_values(self, obj):
        """é€’å½’æ¸…ç†å¯¹è±¡ä¸­çš„NaNå€¼"""
        if isinstance(obj, dict):
            return {k: self.clean_nan_values(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [self.clean_nan_values(item) for item in obj]
        elif isinstance(obj, float) and np.isnan(obj):
            return None  # å°†NaNè½¬æ¢ä¸ºNone (JSONä¸­çš„null)
        else:
            return obj

    def save_to_json(self, data, filename='analytics.json'):
        """ä¿å­˜åˆ°JSONï¼Œç¡®ä¿æ¸…ç†NaNå€¼"""
        print(f"ä¿å­˜æ•°æ®åˆ° data/{filename}...")

        # æ¸…ç†NaNå€¼
        print("æ¸…ç†NaNå€¼...")
        clean_data = self.clean_nan_values(data)

        os.makedirs('data', exist_ok=True)
        filepath = f"data/{filename}"

        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(clean_data, f, ensure_ascii=False, indent=2)

        print(f"æ•°æ®å·²ä¿å­˜åˆ° {filepath}ï¼Œå·²æ¸…ç†æ‰€æœ‰NaNå€¼")

        stats = data['stats']
        print(f"\n=== å¿«é€Ÿå¤„ç†å®Œæˆ ===")
        print(f"ç”¨æˆ·æ€»æ•°: {stats['total_users']}")
        print(f"æ¶ˆæ¯æ€»æ•°: {stats['total_messages']}")
        print(f"ç¾¤ç»„æ•°é‡: {stats['total_groups']}")
        print(f"å‘è¨€é‡åˆ†å¸ƒ: {stats['message_volume_distribution']}")
        print(f"å†…å®¹ç±»å‹åˆ†å¸ƒ: {stats['content_type_distribution']}")

def main():
    print("=== å¿«é€Ÿç”¨æˆ·ç”»åƒå¤„ç†å™¨ ===")

    processor = FastUserProfileProcessor()
    analytics_data = processor.generate_fast_analytics()

    if analytics_data:
        processor.save_to_json(analytics_data)
        print("\nâœ… å¿«é€Ÿå¤„ç†å®Œæˆï¼ç°åœ¨å¯ä»¥å¯åŠ¨å‰ç«¯ç•Œé¢æŸ¥çœ‹ç»“æœã€‚")
    else:
        print("âŒ å¤„ç†å¤±è´¥ï¼")

if __name__ == "__main__":
    main()