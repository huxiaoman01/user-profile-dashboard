#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç”¨æˆ·ç”»åƒ7ç»´åº¦æ·±åº¦æ•°æ®å¤„ç†è„šæœ¬
åŸºäºåŸå§‹èŠå¤©æ•°æ®ç”Ÿæˆå¤šç»´åº¦ç”¨æˆ·ç”»åƒåˆ†ææ•°æ®
"""

import pandas as pd
import numpy as np
import json
import re
from collections import Counter, defaultdict
from datetime import datetime, timedelta
import jieba
import os

class EnhancedUserProfileProcessor:
    def __init__(self):
        """åˆå§‹åŒ–å¤„ç†å™¨"""
        self.users_df = None
        self.messages_df = None
        self.processed_users = {}

        # å‘è¨€ç±»å‹åˆ†ç±»å…³é”®è¯åº“
        self.content_type_keywords = {
            'æŠ€æœ¯å‹': ['ç¼–ç¨‹', 'ä»£ç ', 'ç®—æ³•', 'æ•°æ®ç»“æ„', 'å¼€å‘', 'æŠ€æœ¯', 'ç¨‹åº', 'java', 'python', 'C++', 'è½¯ä»¶', 'ç³»ç»Ÿ', 'æœåŠ¡å™¨', 'æ•°æ®åº“'],
            'è€ƒè¯•å‹': ['è€ƒè¯•', 'å¤ä¹ ', 'é¢˜ç›®', 'ç­”æ¡ˆ', 'æˆç»©', 'åˆ†æ•°', 'è¯•å·', 'è€ƒç ”', 'æœŸæœ«', 'æœŸä¸­', 'ä½œä¸š', 'ç»ƒä¹ '],
            'å­¦ä¹ æ–¹æ³•å‹': ['å­¦ä¹ ', 'æ–¹æ³•', 'æŠ€å·§', 'æ•ˆç‡', 'è®¡åˆ’', 'ç¬”è®°', 'æ€»ç»“', 'ç»éªŒ', 'å»ºè®®', 'å¦‚ä½•å­¦', 'æ€ä¹ˆå­¦'],
            'ç”Ÿæ´»æ–¹å¼å‹': ['å®¿èˆ', 'é£Ÿå ‚', 'ç”Ÿæ´»', 'ä½œæ¯', 'ç¡è§‰', 'èµ·åºŠ', 'åƒé¥­', 'è´­ç‰©', 'æ—¥å¸¸', 'ä¹ æƒ¯'],
            'å¨±ä¹æç¬‘å‹': ['å“ˆå“ˆ', 'ç¬‘æ­»', 'æœ‰è¶£', 'å¥½ç©', 'æç¬‘', 'æ®µå­', 'æ¢—', 'è¡¨æƒ…åŒ…', 'ğŸ˜‚', 'ğŸ¤£'],
            'é—²èŠå‹': ['èŠå¤©', 'è¯è¯´', 'å¯¹äº†', 'è¯é¢˜', 'éšä¾¿', 'æ— èŠ', 'é—²ç€', 'è°ˆè®º'],
            'è¡¨æƒ…åŒ…å‹': ['[å›¾ç‰‡]', '[è¡¨æƒ…]', 'ğŸ˜Š', 'ğŸ˜‚', 'ğŸ¤”', 'ğŸ‘', 'â¤ï¸', 'ğŸ’ª'],
            'ç¤¾ä¼šæŠ€å·§å‹': ['äººé™…', 'äº¤å¾€', 'ç¤¾äº¤', 'æ²Ÿé€š', 'å…³ç³»', 'æœ‹å‹', 'å›¢é˜Ÿ', 'åˆä½œ', 'å»ºè®®', 'å¤„ç†']
        }

        # æƒ…æ„Ÿåˆ†æå…³é”®è¯
        self.sentiment_keywords = {
            'positive': ['å¥½', 'æ£’', 'èµ', 'ä¸é”™', 'å¾ˆå¥½', 'ä¼˜ç§€', 'å‰å®³', 'åŠ æ²¹', 'æ”¯æŒ', 'å¼€å¿ƒ', 'é«˜å…´', 'æ»¡æ„'],
            'negative': ['ä¸å¥½', 'ç³Ÿç³•', 'å¤±æœ›', 'éš¾è¿‡', 'ç”Ÿæ°”', 'è®¨åŒ', 'çƒ¦', 'ç´¯', 'å›°éš¾', 'é—®é¢˜', 'éº»çƒ¦']
        }

        # æé—®å…³é”®è¯
        self.question_keywords = ['ï¼Ÿ', '?', 'å—', 'å‘¢', 'æ€ä¹ˆ', 'å¦‚ä½•', 'ä¸ºä»€ä¹ˆ', 'ä»€ä¹ˆ', 'å“ªä¸ª', 'å“ªé‡Œ', 'æ±‚åŠ©', 'è¯·é—®']

        # é™„å’Œè¯
        self.agreement_words = ['æ˜¯çš„', 'å¯¹', 'å¯¹çš„', 'æ²¡é”™', 'ç¡®å®', 'åŒæ„', 'èµæˆ', 'å¥½çš„', 'å—¯', 'å“ˆå“ˆ', 'ğŸ‘']

    def load_data(self):
        """åŠ è½½åŸå§‹CSVæ•°æ®"""
        print("æ­£åœ¨åŠ è½½æ•°æ®...")
        base_path = "ç”¨äºæ•°æ®åˆ†æçš„ç”¨æˆ·æ•°æ®/data_backup_0901"

        try:
            self.users_df = pd.read_csv(f"{base_path}/users_enhanced.csv", encoding='utf-8')
            messages_df1 = pd.read_csv(f"{base_path}/messages_backup_data_enhanced.csv", encoding='utf-8')
            messages_df2 = pd.read_csv(f"{base_path}/messages_maibot_main_enhanced.csv", encoding='utf-8')

            # åˆå¹¶æ¶ˆæ¯æ•°æ®ï¼Œåªè¿‡æ»¤æ­¦å°çººæœºå™¨äºº
            self.messages_df = pd.concat([messages_df1, messages_df2], ignore_index=True)
            # åªè¿‡æ»¤æ­¦å°çººæœºå™¨äºº(user_id: 3655943918)ï¼Œå…¶ä»–ç”¨æˆ·éƒ½æ˜¯çœŸå®ç”¨æˆ·
            self.messages_df = self.messages_df[
                (self.messages_df['user_id'] != 3655943918) &
                (self.messages_df['user_nickname'] != 'æ­¦å°çºº')
            ]

            print(f"åŠ è½½å®Œæˆï¼šç”¨æˆ·æ•°æ® {len(self.users_df)} æ¡ï¼Œæ¶ˆæ¯æ•°æ® {len(self.messages_df)} æ¡")
            return True

        except Exception as e:
            print(f"æ•°æ®åŠ è½½å¤±è´¥ï¼š{e}")
            return False

    def calculate_message_volume_dimension(self, user_messages):
        """è®¡ç®—å‘è¨€é‡ç»´åº¦åˆ†æ"""
        total_messages = len(user_messages)
        if total_messages == 0:
            return {
                'level': 'æå°‘å‘è¨€äºº',
                'total_messages': 0,
                'avg_length': 0,
                'daily_average': 0,
                'rank': 0,
                'percentile': 0
            }

        # è®¡ç®—å¹³å‡æ¶ˆæ¯é•¿åº¦
        avg_length = user_messages['message_content'].fillna('').astype(str).str.len().mean()

        # è®¡ç®—æ—¥å‡æ¶ˆæ¯æ•°
        date_range = user_messages['date'].nunique()
        daily_average = total_messages / max(date_range, 1)

        return {
            'total_messages': total_messages,
            'avg_length': round(avg_length, 1),
            'daily_average': round(daily_average, 1)
        }

    def calculate_time_pattern_dimension(self, user_messages):
        """è®¡ç®—æ—¶é—´ä¹ æƒ¯ç»´åº¦åˆ†æ"""
        if len(user_messages) == 0:
            return {'type': 'æœªçŸ¥', 'distribution': {}, 'peak_hours': []}

        # æ—¶é—´æ®µåˆ†å¸ƒç»Ÿè®¡
        hour_counts = user_messages['hour'].value_counts()
        total_messages = len(user_messages)

        time_distribution = {
            'æ—©ä¸Š(6-10)': user_messages[(user_messages['hour'] >= 6) & (user_messages['hour'] < 10)].shape[0] / total_messages,
            'ä¸Šåˆ(10-12)': user_messages[(user_messages['hour'] >= 10) & (user_messages['hour'] < 12)].shape[0] / total_messages,
            'ä¸‹åˆ(12-18)': user_messages[(user_messages['hour'] >= 12) & (user_messages['hour'] < 18)].shape[0] / total_messages,
            'æ™šä¸Š(18-23)': user_messages[(user_messages['hour'] >= 18) & (user_messages['hour'] < 23)].shape[0] / total_messages,
            'æ·±å¤œ(23-6)': user_messages[((user_messages['hour'] >= 23) | (user_messages['hour'] < 6))].shape[0] / total_messages
        }

        # åˆ†ç±»é€»è¾‘
        if time_distribution['æ—©ä¸Š(6-10)'] > 0.4:
            time_type = 'æ—©ä¸Šå‹'
        elif time_distribution['æ·±å¤œ(23-6)'] > 0.3:
            time_type = 'ç†¬å¤œå‹'
        elif time_distribution['ä¸Šåˆ(10-12)'] + time_distribution['ä¸‹åˆ(12-18)'] + time_distribution['æ™šä¸Š(18-23)'] > 0.8:
            time_type = 'ä½œæ¯è§„å¾‹å‹'
        else:
            # æ£€æŸ¥æ˜¯å¦åœ¨3ä¸ªä»¥ä¸Šæ—¶é—´æ®µéƒ½æœ‰20%å‘è¨€
            active_periods = sum(1 for ratio in time_distribution.values() if ratio > 0.2)
            if active_periods >= 3:
                time_type = 'ä¸è§„å¾‹ä½œæ¯å‹'
            else:
                time_type = 'ä½œæ¯è§„å¾‹å‹'

        # è·å–æœ€æ´»è·ƒçš„3ä¸ªå°æ—¶
        peak_hours = hour_counts.head(3).index.tolist()

        return {
            'type': time_type,
            'distribution': {k: round(v, 3) for k, v in time_distribution.items()},
            'peak_hours': peak_hours,
            'hourly_stats': hour_counts.to_dict()
        }

    def calculate_content_type_dimension(self, user_messages):
        """è®¡ç®—å‘è¨€ç±»å‹ç»´åº¦åˆ†æ"""
        if len(user_messages) == 0:
            return {'primary_type': 'æœªçŸ¥', 'distribution': {}}

        # ç»Ÿè®¡å„ç±»å‹å…³é”®è¯å‡ºç°æ¬¡æ•°
        type_scores = defaultdict(int)
        total_messages = len(user_messages)

        for _, message in user_messages.iterrows():
            content = str(message.get('message_content', ''))

            for content_type, keywords in self.content_type_keywords.items():
                for keyword in keywords:
                    if keyword in content:
                        type_scores[content_type] += 1
                        break  # æ¯æ¡æ¶ˆæ¯æ¯ç§ç±»å‹æœ€å¤šè®¡1åˆ†

        if not type_scores:
            return {
                'primary_type': 'é—²èŠå‹',
                'distribution': {'é—²èŠå‹': 1.0}
            }

        # è®¡ç®—åˆ†å¸ƒæ¯”ä¾‹
        total_scored = sum(type_scores.values())
        distribution = {k: v/total_scored for k, v in type_scores.items()}

        # ç¡®å®šä¸»è¦ç±»å‹
        primary_type = max(distribution.keys(), key=lambda k: distribution[k])

        return {
            'primary_type': primary_type,
            'distribution': {k: round(v, 3) for k, v in distribution.items()}
        }

    def calculate_social_behavior_dimension(self, user_messages, all_messages):
        """è®¡ç®—ç¤¾äº¤è¡Œä¸ºç»´åº¦åˆ†æ"""
        if len(user_messages) == 0:
            return {'type': 'æœªçŸ¥', 'metrics': {}}

        user_id = user_messages.iloc[0]['user_id']
        total_messages = len(user_messages)

        # è®¡ç®—å„é¡¹æŒ‡æ ‡

        # 1. è¯é¢˜å‘èµ·ç‡ - é¦–æ¡æ¶ˆæ¯æ¯”ä¾‹ï¼ˆç®€åŒ–ç‰ˆï¼šæ²¡æœ‰å›å¤å…³ç³»çš„æ¶ˆæ¯ï¼‰
        non_reply_messages = user_messages[user_messages['reply_to'].isna() | (user_messages['reply_to'] == '')]
        initiate_rate = len(non_reply_messages) / total_messages

        # 2. å›å¤ç‡ - æœ‰å›å¤å…³ç³»çš„æ¶ˆæ¯æ¯”ä¾‹
        reply_messages = user_messages[user_messages['reply_to'].notna() & (user_messages['reply_to'] != '')]
        reply_rate = len(reply_messages) / total_messages

        # 3. æé—®ç‡
        question_count = 0
        for _, message in user_messages.iterrows():
            content = str(message.get('message_content', ''))
            if any(keyword in content for keyword in self.question_keywords):
                question_count += 1
        question_rate = question_count / total_messages

        # 4. é™„å’Œç‡
        agreement_count = 0
        for _, message in user_messages.iterrows():
            content = str(message.get('message_content', ''))
            if any(word in content for word in self.agreement_words):
                agreement_count += 1
        agreement_rate = agreement_count / total_messages

        # 5. è¢«@é¢‘ç‡ï¼ˆç®€åŒ–ç‰ˆï¼šæ£€æŸ¥å…¶ä»–äººæ¶ˆæ¯ä¸­æ˜¯å¦æåˆ°è¯¥ç”¨æˆ·ï¼‰
        user_nickname = user_messages.iloc[0]['user_nickname']
        mentioned_count = 0
        for _, message in all_messages.iterrows():
            if message['user_id'] != user_id:  # å…¶ä»–äººçš„æ¶ˆæ¯
                content = str(message.get('message_content', ''))
                if f'@{user_nickname}' in content or user_nickname in content:
                    mentioned_count += 1
        mention_rate = mentioned_count / len(all_messages) if len(all_messages) > 0 else 0

        # ç¤¾äº¤ç±»å‹åˆ¤æ–­ - ç»Ÿä¸€æ ‡å‡†
        # è®¡ç®—ç»¼åˆç¤¾äº¤è¯„åˆ†
        interaction_score = (initiate_rate * 40 + question_rate * 30 + reply_rate * 20 + mention_rate * 100) * 100
        influence_score = (initiate_rate * 50 + question_rate * 30 + agreement_rate * 20) * 100

        # ç»Ÿä¸€åˆ†ç±»æ ‡å‡†
        if initiate_rate > 0.25 or question_rate > 0.15:
            social_type = 'ä¸»åŠ¨ç¤¾äº¤å‹'
        elif reply_rate > 0.5 or agreement_rate > 0.25:
            social_type = 'ç¤¾äº¤é™„å’Œå‹'
        elif mention_rate > 0.001 and reply_rate > 0.3:  # è¢«æåŠä¸”æœ‰å›åº”
            social_type = 'è¢«åŠ¨ç¤¾äº¤å‹'
        else:
            social_type = 'ç¤¾äº¤è§‚å¯Ÿå‹'

        return {
            'type': social_type,
            'metrics': {
                'initiate_rate': round(initiate_rate, 3),
                'reply_rate': round(reply_rate, 3),
                'question_rate': round(question_rate, 3),
                'agreement_rate': round(agreement_rate, 3),
                'mention_rate': round(mention_rate, 5),
                'interactionScore': round(interaction_score, 1),
                'influenceScore': round(influence_score, 1),
                # ä¸ºå‰ç«¯æä¾›ç™¾åˆ†æ¯”æ ¼å¼çš„æ•°æ®
                'firstMessageRatio': round(initiate_rate * 100, 1),
                'questionFrequency': round(question_rate * 100, 1),
                'mentionFrequency': round(mention_rate * 1000, 1),  # è½¬æ¢ä¸ºåƒåˆ†æ¯”
                'replyRatio': round(reply_rate * 100, 1),
                'beMentionedRatio': round(mention_rate * 100, 1)
            }
        }

    def calculate_sentiment_dimension(self, user_messages):
        """è®¡ç®—æƒ…æ„Ÿå€¾å‘ç»´åº¦åˆ†æ"""
        if len(user_messages) == 0:
            return {'overall_sentiment': 'ä¸­æ€§', 'positive_ratio': 0.5, 'negative_ratio': 0.5}

        positive_count = 0
        negative_count = 0

        for _, message in user_messages.iterrows():
            content = str(message.get('message_content', ''))

            # æ£€æŸ¥ç§¯æè¯æ±‡
            if any(word in content for word in self.sentiment_keywords['positive']):
                positive_count += 1

            # æ£€æŸ¥æ¶ˆæè¯æ±‡
            if any(word in content for word in self.sentiment_keywords['negative']):
                negative_count += 1

        total_emotional = positive_count + negative_count
        if total_emotional == 0:
            return {
                'overall_sentiment': 'ä¸­æ€§',
                'positive_ratio': 0.5,
                'negative_ratio': 0.5
            }

        positive_ratio = positive_count / total_emotional
        negative_ratio = negative_count / total_emotional

        # åˆ¤æ–­æ•´ä½“æƒ…æ„Ÿå€¾å‘
        if positive_ratio > 0.6:
            overall_sentiment = 'ç§¯æå‹'
        elif negative_ratio > 0.6:
            overall_sentiment = 'æ¶ˆæå‹'
        else:
            overall_sentiment = 'ä¸­æ€§'

        return {
            'overall_sentiment': overall_sentiment,
            'positive_ratio': round(positive_ratio, 3),
            'negative_ratio': round(negative_ratio, 3)
        }

    def calculate_interaction_style_dimension(self, user_messages):
        """è®¡ç®—æé—®å›ç­”ç»´åº¦åˆ†æ"""
        if len(user_messages) == 0:
            return {'type': 'æœªçŸ¥', 'question_ratio': 0, 'answer_ratio': 0}

        total_messages = len(user_messages)
        question_count = 0
        answer_count = 0

        for _, message in user_messages.iterrows():
            content = str(message.get('message_content', ''))

            # æ£€æŸ¥æ˜¯å¦ä¸ºæé—®
            if any(keyword in content for keyword in self.question_keywords):
                question_count += 1

            # æ£€æŸ¥æ˜¯å¦ä¸ºå›ç­”ï¼ˆåŒ…å«å›å¤å…³ç³»æˆ–ç­”æ¡ˆæ€§è´¨çš„è¯æ±‡ï¼‰
            if (message.get('reply_to') and message.get('reply_to') != '') or \
               any(word in content for word in ['ç­”æ¡ˆ', 'è§£é‡Š', 'æ–¹æ³•', 'æ­¥éª¤', 'å»ºè®®', 'å¯ä»¥', 'åº”è¯¥']):
                answer_count += 1

        question_ratio = question_count / total_messages
        answer_ratio = answer_count / total_messages

        # åˆ¤æ–­äº’åŠ¨é£æ ¼
        if question_ratio > 0.4:
            interaction_type = 'æé—®å‹'
        elif answer_ratio > 0.4:
            interaction_type = 'å›ç­”å‹'
        else:
            interaction_type = 'å¹³è¡¡å‹'

        return {
            'type': interaction_type,
            'question_ratio': round(question_ratio, 3),
            'answer_ratio': round(answer_ratio, 3)
        }

    def process_single_user(self, user_id, user_info, user_messages, all_messages):
        """å¤„ç†å•ä¸ªç”¨æˆ·çš„å¤šç»´åº¦åˆ†æ"""

        # åŸºç¡€ä¿¡æ¯
        basic_info = {
            'user_id': str(user_id),
            'nickname': user_info.get('nickname', 'æœªçŸ¥ç”¨æˆ·'),
            'main_group': user_info.get('group_name', 'æœªçŸ¥ç¾¤ç»„'),
            'all_groups': user_info.get('all_groups', [user_info.get('group_name', 'æœªçŸ¥ç¾¤ç»„')]),
            'platform': user_info.get('platform', 'unknown')
        }

        # 7ç»´åº¦åˆ†æ
        dimensions = {
            'message_volume': self.calculate_message_volume_dimension(user_messages),
            'time_pattern': self.calculate_time_pattern_dimension(user_messages),
            'content_type': self.calculate_content_type_dimension(user_messages),
            'social_behavior': self.calculate_social_behavior_dimension(user_messages, all_messages),
            'sentiment': self.calculate_sentiment_dimension(user_messages),
            'interaction_style': self.calculate_interaction_style_dimension(user_messages),
            'member_status': {
                'type': 'æ–°æˆå‘˜' if len(user_messages) < 50 else 'è€æˆå‘˜',  # ç®€åŒ–åˆ¤æ–­
                'days_active': user_messages['date'].nunique() if len(user_messages) > 0 and 'date' in user_messages.columns else 0
            }
        }

        # ç”Ÿæˆç»¼åˆæ ‡ç­¾
        tags = []

        # å‘è¨€é‡æ ‡ç­¾
        msg_count = dimensions['message_volume']['total_messages']
        if msg_count > 200:
            tags.append('ğŸ”¥è¯é¢˜ä¸»å¯¼è€…')
        elif msg_count > 50:
            tags.append('ğŸ’¬ç¨³å®šå‘è¨€äºº')
        elif msg_count > 10:
            tags.append('ğŸ¤å¶å°”å‘è¨€')
        else:
            tags.append('ğŸ‘€æ½œæ°´è§‚å¯Ÿ')

        # å‘è¨€ç±»å‹æ ‡ç­¾
        content_type = dimensions['content_type']['primary_type']
        type_emoji = {
            'æŠ€æœ¯å‹': 'ğŸ’»', 'è€ƒè¯•å‹': 'ğŸ“', 'å­¦ä¹ æ–¹æ³•å‹': 'ğŸ“š', 'ç”Ÿæ´»æ–¹å¼å‹': 'ğŸ ',
            'å¨±ä¹æç¬‘å‹': 'ğŸ˜„', 'é—²èŠå‹': 'ğŸ’­', 'è¡¨æƒ…åŒ…å‹': 'ğŸ˜Š', 'ç¤¾ä¼šæŠ€å·§å‹': 'ğŸ¤'
        }
        tags.append(f"{type_emoji.get(content_type, 'ğŸ’­')}{content_type}")

        # æ—¶é—´ä¹ æƒ¯æ ‡ç­¾
        time_type = dimensions['time_pattern']['type']
        time_emoji = {'æ—©ä¸Šå‹': 'ğŸŒ…', 'ç†¬å¤œå‹': 'ğŸŒ™', 'ä½œæ¯è§„å¾‹å‹': 'â°', 'ä¸è§„å¾‹ä½œæ¯å‹': 'ğŸ”€'}
        tags.append(f"{time_emoji.get(time_type, 'â°')}{time_type}")

        # ç¤¾äº¤è¡Œä¸ºæ ‡ç­¾
        social_type = dimensions['social_behavior']['type']
        social_emoji = {'ä¸»åŠ¨ç¤¾äº¤å‹': 'ğŸš€', 'ç¤¾äº¤é™„å’Œå‹': 'ğŸ‘', 'è¢«åŠ¨ç¤¾äº¤å‹': 'ğŸ“¢', 'ä¸€èˆ¬ç¤¾äº¤å‹': 'ğŸ¤'}
        tags.append(f"{social_emoji.get(social_type, 'ğŸ¤')}{social_type}")

        # æƒ…æ„Ÿå€¾å‘æ ‡ç­¾
        sentiment = dimensions['sentiment']['overall_sentiment']
        sentiment_emoji = {'ç§¯æå‹': 'â˜€ï¸', 'æ¶ˆæå‹': 'â˜ï¸', 'ä¸­æ€§': 'ğŸ˜'}
        tags.append(f"{sentiment_emoji.get(sentiment, 'ğŸ˜')}{sentiment}")

        # ç”Ÿæˆæè¿°
        description_parts = []
        if content_type != 'æœªçŸ¥':
            description_parts.append(f"{content_type}çš„")
        if time_type == 'ç†¬å¤œå‹':
            description_parts.append("æ·±å¤œæ´»è·ƒ")
        elif time_type == 'æ—©ä¸Šå‹':
            description_parts.append("æ—©èµ·æ´»è·ƒ")

        if social_type == 'ä¸»åŠ¨ç¤¾äº¤å‹':
            description_parts.append("å–„äºå‘èµ·è®¨è®º")
        elif social_type == 'ç¤¾äº¤é™„å’Œå‹':
            description_parts.append("ä¹äºå›åº”ä»–äºº")

        description = "ã€".join(description_parts) if description_parts else "ç¾¤èŠå‚ä¸è€…"

        # æ„å»ºå®Œæ•´ç”¨æˆ·ç”»åƒ
        user_profile = {
            **basic_info,
            'dimensions': dimensions,
            'profile_summary': {
                'tags': tags,
                'description': description,
                'message_count': msg_count,
                'active_days': user_messages['date'].nunique() if len(user_messages) > 0 and 'date' in user_messages.columns else 0
            }
        }

        return user_profile

    def process_all_users(self):
        """å¤„ç†æ‰€æœ‰ç”¨æˆ·æ•°æ®"""
        print("å¼€å§‹å¤„ç†ç”¨æˆ·ç”»åƒ...")

        # æŒ‰ç”¨æˆ·IDåˆ†ç»„ç»Ÿè®¡æ¶ˆæ¯
        user_message_groups = self.messages_df.groupby('user_id')

        # å¤„ç†ç”¨æˆ·åŸºç¡€ä¿¡æ¯å»é‡
        user_info_dict = {}
        for _, user_row in self.users_df.iterrows():
            user_id = user_row['user_id']
            if user_id not in user_info_dict:
                user_info_dict[user_id] = {
                    'nickname': user_row['nickname'],
                    'group_name': user_row['group_name'],
                    'platform': user_row['platform'],
                    'all_groups': [user_row['group_name']]
                }
            else:
                # åˆå¹¶ç¾¤ç»„ä¿¡æ¯
                if user_row['group_name'] not in user_info_dict[user_id]['all_groups']:
                    user_info_dict[user_id]['all_groups'].append(user_row['group_name'])

        processed_users = []
        total_users = len(user_info_dict)

        for i, (user_id, user_info) in enumerate(user_info_dict.items()):
            if i % 50 == 0:
                print(f"å¤„ç†è¿›åº¦: {i+1}/{total_users}")

            # è·å–è¯¥ç”¨æˆ·çš„æ‰€æœ‰æ¶ˆæ¯
            if user_id in user_message_groups.groups:
                user_messages = user_message_groups.get_group(user_id)
            else:
                user_messages = pd.DataFrame()  # ç©ºDataFrame

            # å¤„ç†è¯¥ç”¨æˆ·
            user_profile = self.process_single_user(user_id, user_info, user_messages, self.messages_df)
            processed_users.append(user_profile)

        print(f"ç”¨æˆ·ç”»åƒå¤„ç†å®Œæˆï¼Œå…±å¤„ç† {len(processed_users)} ä¸ªç”¨æˆ·")
        return processed_users

    def calculate_global_statistics(self, users_data):
        """è®¡ç®—å…¨å±€ç»Ÿè®¡æ•°æ®"""
        print("è®¡ç®—å…¨å±€ç»Ÿè®¡...")

        # ç”¨æˆ·åˆ†ç±»ç»Ÿè®¡
        message_volume_stats = Counter()
        time_pattern_stats = Counter()
        content_type_stats = Counter()
        social_behavior_stats = Counter()
        sentiment_stats = Counter()

        total_messages = 0

        for user in users_data:
            dims = user['dimensions']

            # å‘è¨€é‡åˆ†ç±»ï¼ˆæ ¹æ®å®é™…æ¶ˆæ¯æ•°åŠ¨æ€åˆ†ç±»ï¼‰
            msg_count = dims['message_volume']['total_messages']
            total_messages += msg_count

        # è®¡ç®—å‘è¨€é‡åˆ†ç±»é˜ˆå€¼
        message_counts = [user['dimensions']['message_volume']['total_messages'] for user in users_data]
        message_counts.sort(reverse=True)

        total_users = len(message_counts)
        thresholds = {
            'major_speaker': message_counts[int(total_users * 0.15)] if total_users > 10 else 100,
            'stable_speaker': message_counts[int(total_users * 0.60)] if total_users > 10 else 20,
            'occasional_speaker': message_counts[int(total_users * 0.85)] if total_users > 10 else 5
        }

        # é‡æ–°åˆ†ç±»ç”¨æˆ·å¹¶ç»Ÿè®¡
        for user in users_data:
            msg_count = user['dimensions']['message_volume']['total_messages']

            # å‘è¨€é‡åˆ†ç±»
            if msg_count >= thresholds['major_speaker']:
                volume_level = 'ä¸»è¦å‘è¨€äºº'
            elif msg_count >= thresholds['stable_speaker']:
                volume_level = 'ç¨³å®šå‘è¨€äºº'
            elif msg_count >= thresholds['occasional_speaker']:
                volume_level = 'å°‘é‡å‘è¨€äºº'
            else:
                volume_level = 'æå°‘å‘è¨€äºº'

            # æ›´æ–°ç”¨æˆ·çš„å‘è¨€é‡åˆ†ç±»
            user['dimensions']['message_volume']['level'] = volume_level
            message_volume_stats[volume_level] += 1

            # å…¶ä»–ç»´åº¦ç»Ÿè®¡
            time_pattern_stats[user['dimensions']['time_pattern']['type']] += 1
            content_type_stats[user['dimensions']['content_type']['primary_type']] += 1
            social_behavior_stats[user['dimensions']['social_behavior']['type']] += 1
            sentiment_stats[user['dimensions']['sentiment']['overall_sentiment']] += 1

        # ç¾¤ç»„ç»Ÿè®¡
        group_stats = Counter()
        for user in users_data:
            for group in user['all_groups']:
                group_stats[group] += 1

        return {
            'total_users': total_users,
            'total_messages': total_messages,
            'total_groups': len(group_stats),
            'message_volume_distribution': dict(message_volume_stats),
            'time_pattern_distribution': dict(time_pattern_stats),
            'content_type_distribution': dict(content_type_stats),
            'social_behavior_distribution': dict(social_behavior_stats),
            'sentiment_distribution': dict(sentiment_stats),
            'group_distribution': dict(group_stats),
            'thresholds': thresholds,
            'update_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }

    def generate_enhanced_analytics(self):
        """ç”Ÿæˆå¢å¼ºç‰ˆåˆ†ææ•°æ®"""
        if not self.load_data():
            return None

        # å¤„ç†æ‰€æœ‰ç”¨æˆ·
        users_data = self.process_all_users()

        # è®¡ç®—å…¨å±€ç»Ÿè®¡
        global_stats = self.calculate_global_statistics(users_data)

        # æ„å»ºæœ€ç»ˆæ•°æ®ç»“æ„
        analytics_data = {
            'stats': global_stats,
            'users': users_data,
            'metadata': {
                'processing_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'data_source': 'enhanced_csv_processing',
                'dimensions_count': 7,
                'features': [
                    'message_volume_classification',
                    'time_pattern_analysis',
                    'content_type_classification',
                    'social_behavior_analysis',
                    'sentiment_analysis',
                    'interaction_style_analysis',
                    'member_status_analysis'
                ]
            }
        }

        return analytics_data

    def save_to_json(self, data, filename='enhanced_analytics.json'):
        """ä¿å­˜å¤„ç†ç»“æœåˆ°JSONæ–‡ä»¶"""
        print(f"ä¿å­˜æ•°æ®åˆ° {filename}...")

        # ç¡®ä¿dataç›®å½•å­˜åœ¨
        os.makedirs('data', exist_ok=True)

        filepath = f"data/{filename}"
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        print(f"æ•°æ®ä¿å­˜å®Œæˆï¼š{filepath}")

        # æ˜¾ç¤ºç»Ÿè®¡æ‘˜è¦
        stats = data['stats']
        print(f"\n=== å¤„ç†ç»“æœæ‘˜è¦ ===")
        print(f"ç”¨æˆ·æ€»æ•°: {stats['total_users']}")
        print(f"æ¶ˆæ¯æ€»æ•°: {stats['total_messages']}")
        print(f"ç¾¤ç»„æ•°é‡: {stats['total_groups']}")
        print(f"\nå‘è¨€é‡åˆ†å¸ƒ: {stats['message_volume_distribution']}")
        print(f"æ—¶é—´ä¹ æƒ¯åˆ†å¸ƒ: {stats['time_pattern_distribution']}")
        print(f"å‘è¨€ç±»å‹åˆ†å¸ƒ: {stats['content_type_distribution']}")


def main():
    """ä¸»å‡½æ•°"""
    print("=== ç”¨æˆ·ç”»åƒ7ç»´åº¦æ·±åº¦æ•°æ®å¤„ç† ===")

    processor = EnhancedUserProfileProcessor()

    # ç”Ÿæˆå¢å¼ºåˆ†ææ•°æ®
    analytics_data = processor.generate_enhanced_analytics()

    if analytics_data:
        # ä¿å­˜åˆ°JSONæ–‡ä»¶
        processor.save_to_json(analytics_data)

        # åŒæ—¶ä¿å­˜ä¸€ä»½å¤‡ä»½åˆ°åŸæ–‡ä»¶åï¼ˆå…¼å®¹ç°æœ‰å‰ç«¯ï¼‰
        processor.save_to_json(analytics_data, 'analytics.json')

        print("\nå¤„ç†å®Œæˆï¼æ–°çš„åˆ†ææ•°æ®å·²ç”Ÿæˆï¼Œæ”¯æŒ7ç»´åº¦ç”¨æˆ·ç”»åƒåˆ†æã€‚")
    else:
        print("æ•°æ®å¤„ç†å¤±è´¥ï¼")


if __name__ == "__main__":
    main()